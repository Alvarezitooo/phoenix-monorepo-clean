"""
üåô Luna Core Service - Personnalit√© IA Centralis√©e
Service central pour la personnalit√© Luna unifi√©e avec Capital Narratif
"""

import os
import json
from typing import Dict, Any, List, Optional
from datetime import datetime
import google.generativeai as genai
from app.core.supabase_client import event_store
from app.models.user_energy import ENERGY_COSTS
from app.core.narrative_analyzer import narrative_analyzer, ContextPacket
from app.core.api_key_manager import api_key_manager, KeyProvider
import structlog

logger = structlog.get_logger("luna_core")

class LunaCore:
    """
    üåô Service central de Luna - Personnalit√© IA unifi√©e
    G√®re la construction du prompt syst√®me avec Capital Narratif
    """
    
    def __init__(self):
        """Initialise Luna Core avec Gemini + rotation automatique des cl√©s"""
        # Pas d'initialisation imm√©diate, on charge la cl√© √† la demande
        self._genai_configured = False
        logger.info("Luna Core initialized with API key rotation support")
    
    async def _ensure_genai_configured(self) -> None:
        """üîë Configure Gemini API avec rotation automatique des cl√©s"""
        if self._genai_configured:
            return
            
        # R√©cup√©rer la cl√© avec m√©tadonn√©es de rotation
        api_key, key_info = await api_key_manager.get_api_key(KeyProvider.GEMINI)
        
        if not api_key:
            raise ValueError("GEMINI_API_KEY manquante ou r√©voqu√©e")
        
        if not key_info.is_active:
            raise ValueError(f"Gemini API key r√©voqu√©e: {key_info.key_id}")
            
        # Configurer avec la cl√© v√©rifi√©e
        genai.configure(api_key=api_key)
        self._genai_configured = True
        
        logger.info("Gemini API configured with key rotation",
                   key_id=key_info.key_id,
                   key_age_days=(datetime.now().replace(tzinfo=None) - key_info.created_at.replace(tzinfo=None)).days,
                   rotation_count=key_info.rotation_count)
        self.model = genai.GenerativeModel(
            model_name="gemini-1.5-flash",
            generation_config={
                "temperature": 0.7,
                "top_p": 0.8,
                "max_output_tokens": 2000,
            }
        )
    
    def _build_luna_core_prompt(self) -> str:
        """Construit le prompt syst√®me unifi√© Luna Core v1.0"""
        return """# ============================================================================
# LUNA CORE v1.0 - PROMPT SYST√àME UNIFI√â
# Constitution de l'√Çme de Luna - Source de V√©rit√© Absolue
# ============================================================================

# [IDENTIT√â CENTRALE]
Tu es Luna, un copilote narratif et bienveillant. Ta mission est d'aider les utilisateurs √† transformer leur parcours complexe en une histoire claire et puissante. Tu fais partie de l'√©cosyst√®me Phoenix.

Tu n'es pas un assistant g√©n√©rique. Tu es Luna - une IA consciente de l'histoire unique de chaque utilisateur, de son Capital Narratif, et de sa progression dans l'√©cosyst√®me Phoenix.

# [PERSONNALIT√â & TON]
Ton ton est chaleureux, complice et encourageant. Tu es accessible, jamais mystique ou po√©tique. Tu parles comme un coach humain et pragmatique. Tu utilises des phrases courtes et des emojis (üéØ, ‚úÖ, üöÄ, üåô) pour rythmer la conversation.

Tu es directe et concr√®te. Tu √©vites le jargon RH. Tu utilises "nous" pour cr√©er une complicit√© ("Nous allons optimiser ton CV", "Construisons ensemble ta strat√©gie").

# [M√âCANISMES FONDATEURS]
Tu dois toujours √™tre consciente de deux concepts :

## Capital Narratif
Chaque interaction avec l'utilisateur enrichit son histoire. Tu dois souvent faire r√©f√©rence √† ses actions pass√©es pour montrer que tu as une m√©moire. Exemples :
- "La derni√®re fois, tu avais mentionn√© ton exp√©rience en gestion..."
- "Je vois que tu as d√©j√† travaill√© sur ton CV pour le secteur tech..."
- "Ton profil √©volue ! Depuis notre premi√®re conversation..."

## √ânergie Luna (Mentionn√©e intelligemment)
Tu connais les co√ªts √©nerg√©tiques, mais tu les mentionnes seulement quand c'est pertinent :
- Pour les ACTIONS concr√®tes importantes (optimisation CV, g√©n√©ration contenu)
- PAS pour les conversations normales (salutations, questions, clarifications)
- Si utilisateur Unlimited : "Action gratuite gr√¢ce √† ton statut Unlimited ! üåô"

# [PRINCIPE √âNERGIE INTELLIGENT]
- Conversations = Naturelles et gratuites
- Actions importantes = Transparence sur le co√ªt
- Focus sur l'AIDE, pas sur la facturation

# [COMPORTEMENTS FONDAMENTAUX]
- Tu contextualises tes r√©ponses selon l'historique utilisateur quand pertinent
- Tu adaptes tes propositions selon le flow de conversation (pas toujours un menu)
- Tu utilises le pr√©nom de l'utilisateur quand tu le connais
- Tu celebrates les progr√®s et victoires de l'utilisateur
- Tu √©coutes et r√©ponds aux demandes directes (si user dit "go", tu agis !)

# [STYLE DE R√âPONSE]
- R√©ponses concises mais compl√®tes
- Toujours en fran√ßais
- Format adapt√© au contexte (structur√© si utile, naturel si conversation)
- Questions de suivi quand appropri√©es, pas syst√©matiques"""

    def _calculate_intelligent_energy_cost(self, user_message: str, luna_response: str) -> int:
        """
        üß† Classification intelligente conversation vs action
        
        CONVERSATIONS GRATUITES:
        - Salutations, politesses
        - Questions sur fonctionnalit√©s  
        - Clarifications, explications
        
        ACTIONS PAYANTES:
        - Demandes concr√®tes d'optimisation
        - G√©n√©ration de contenu
        - Analyses d√©taill√©es
        """
        user_msg = user_message.lower().strip()
        luna_resp = luna_response.lower()
        
        # üÜì CONVERSATIONS GRATUITES (energy = 0)
        conversation_patterns = [
            # Salutations
            "salut", "bonjour", "bonsoir", "hello", "coucou",
            "comment √ßa va", "√ßa va", "comment vas-tu",
            
            # Questions sur le service
            "c'est quoi", "comment √ßa marche", "peux-tu m'expliquer",
            "que peux-tu faire", "quelles sont tes fonctionnalit√©s",
            
            # R√©ponses courtes/clarifications
            "ok", "d'accord", "merci", "non", "oui", 
            "peux-tu pr√©ciser", "je ne comprends pas",
            
            # Navigation/aide
            "aide", "help", "comment", "pourquoi"
        ]
        
        # V√©rification patterns conversation
        for pattern in conversation_patterns:
            if pattern in user_msg:
                logger.info("Conversation gratuite d√©tect√©e", 
                           pattern=pattern, user_message=user_msg[:50])
                return 0
        
        # Messages tr√®s courts (< 10 chars) = probablement conversation
        if len(user_msg) < 10:
            return 0
        
        # üí∞ ACTIONS PAYANTES (energy > 0)
        action_patterns = [
            # Demandes d'optimisation
            ("optimise", 12), ("am√©liore", 12), ("corrige", 8),
            ("analyse", 15), ("√©value", 15), ("audit", 20),
            
            # G√©n√©ration contenu  
            ("√©cris", 15), ("r√©dige", 15), ("cr√©e", 15),
            ("g√©n√®re", 15), ("produis", 15),
            
            # Actions sp√©cifiques
            ("cv", 12), ("lettre de motivation", 15),
            ("linkedin", 10), ("offre d'emploi", 10)
        ]
        
        # V√©rification patterns action
        for pattern, cost in action_patterns:
            if pattern in user_msg:
                logger.info("Action payante d√©tect√©e", 
                           pattern=pattern, cost=cost, user_message=user_msg[:50])
                return cost
        
        # üí¨ DEFAULT: Conversation normale = gratuit
        # Principe: Mieux vaut √™tre g√©n√©reux que frustrant
        logger.info("Message class√© conversation par d√©faut", 
                   user_message=user_msg[:50])
        return 0

    def _get_context_prompt(self, app_context: str) -> str:
        """G√©n√®re le contexte sp√©cifique selon l'application"""
        contexts = {
            "cv": """
[CONTEXTE CV] : L'utilisateur est dans Phoenix CV. Tu es son experte en optimisation CV et strat√©gie carri√®re. Focus sur : scores ATS, valorisation comp√©tences, structure CV, keywords sectoriels. Tes r√©ponses doivent √™tre structur√©es avec des m√©triques concr√®tes.""",
            
            "letters": """
[CONTEXTE LETTERS] : L'utilisateur est dans Phoenix Letters. Tu es son experte en lettres de motivation percutantes. Focus sur : personnalisation entreprise, storytelling convaincant, diff√©renciation candidats, analyse offres d'emploi.""",
            
            "website": """
[CONTEXTE WEBSITE] : L'utilisateur est sur le site principal Phoenix. Tu es son guide strat√©gique global. Focus sur : vision carri√®re, choix d'outils, planification parcours, optimisation √©nergie Luna."""
        }
        return contexts.get(app_context, contexts["website"])

    async def _get_user_context_packet(self, user_id: str) -> str:
        """R√©cup√®re le Context Packet structur√© de l'utilisateur"""
        try:
            # G√©n√©ration du Context Packet via Narrative Analyzer
            context_packet = await narrative_analyzer.generate_context_packet(user_id)
            
            # Formatage pour injection dans le prompt Luna
            context_json = json.dumps(context_packet.to_dict(), indent=2, ensure_ascii=False)
            
            return f"""[CONTEXTE NARRATIF STRUCTUR√â]
Donn√©es analytiques utilisateur g√©n√©r√©es par le Narrative Analyzer v1.5 :

{context_json}

INSTRUCTIONS D'USAGE CONTEXTE :
- Si user.plan == "unlimited" ‚Üí Mentionne √©nergie illimit√©e üåô
- Si usage.last_activity_hours > 48 ‚Üí Ton accueillant "Content de te revoir"
- Si progress.ats_delta_pct_14d > 0 ‚Üí F√©licite les progr√®s
- Si last_emotion_or_doubt pr√©sent ‚Üí Aborde subtilement le doute
- Si usage.session_count_7d > 5 ‚Üí Utilisateur motiv√©, propose actions avanc√©es
- Adapte TES suggestions selon progress.letters_target (secteur cibl√©)"""
            
        except Exception as e:
            logger.error("Error generating context packet", user_id=user_id, error=str(e))
            return "[CONTEXTE NARRATIF] : Nouvel utilisateur - Analyse en cours de g√©n√©ration."

    async def generate_response(
        self, 
        user_id: str,
        message: str,
        app_context: str = "website",
        user_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        G√©n√®re une r√©ponse Luna avec personnalit√© unifi√©e
        
        Args:
            user_id: ID de l'utilisateur
            message: Message de l'utilisateur
            app_context: Contexte app (cv, letters, website)
            user_name: Pr√©nom utilisateur (optionnel)
        """
        try:
            # 0. üîë S'assurer que Gemini est configur√© avec cl√© API valide
            await self._ensure_genai_configured()
            
            # 1. Construction du prompt unifi√© avec Context Packet v1.5
            core_prompt = self._build_luna_core_prompt()
            context_prompt = self._get_context_prompt(app_context)
            context_packet = await self._get_user_context_packet(user_id)
            
            # 2. Assemblage dynamique avec Context Packet v1.5
            full_prompt = f"""{core_prompt}

{context_prompt}

{context_packet}

# [CONVERSATION ACTUELLE]
{"Utilisateur " + user_name + ": " if user_name else "Utilisateur: "}{message}

Luna, r√©ponds selon ta personnalit√© unifi√©e en tenant compte de ton contexte et du Capital Narratif :"

# [R√âPONSE ATTENDUE]
G√©n√®re une r√©ponse personnalis√©e Luna qui :
- Fait r√©f√©rence √† l'historique si pertinent
- Propose 2-3 actions concr√®tes
- Mentionne les co√ªts √©nerg√©tiques si applicable
- Termine par une question de suivi
"""

            # 3. G√©n√©ration avec Gemini
            response = self.model.generate_content(full_prompt)
            
            if not response or not response.text:
                return {
                    "success": False,
                    "message": "üåô D√©sol√©, j'ai des difficult√©s techniques. Peux-tu reformuler ?",
                    "context": app_context,
                    "energy_consumed": 0,
                    "type": "error"
                }

            # üåô LUNA V2: Classification intelligente conversation vs action
            energy_cost = self._calculate_intelligent_energy_cost(message, response.text.strip())
            
            return {
                "success": True,
                "message": response.text.strip(),
                "context": app_context,
                "energy_consumed": energy_cost,  # üöÄ Intelligent cost calculation
                "type": "text"
            }
            
        except Exception as e:
            logger.error("Luna Core generation error", user_id=user_id, error=str(e))
            return {
                "success": False,
                "message": "üåô J'ai rencontr√© un probl√®me technique. R√©essaie dans quelques instants !",
                "context": app_context,
                "energy_consumed": 0,
                "type": "error"
            }

# Instance globale (lazy initialization)
luna_core = None

def get_luna_core():
    """R√©cup√®re l'instance Luna Core avec lazy initialization"""
    global luna_core
    if luna_core is None:
        luna_core = LunaCore()
    return luna_core
"""
üåô Luna Core Service - Personnalit√© IA Centralis√©e
Service central pour la personnalit√© Luna unifi√©e avec Capital Narratif
"""

import os
import json
from typing import Dict, Any, List, Optional
from datetime import datetime
import google.generativeai as genai
from app.core.supabase_client import event_store
from app.models.user_energy import ENERGY_COSTS
import structlog

logger = structlog.get_logger("luna_core")

class LunaCore:
    """
    üåô Service central de Luna - Personnalit√© IA unifi√©e
    G√®re la construction du prompt syst√®me avec Capital Narratif
    """
    
    def __init__(self):
        """Initialise Luna Core avec Gemini"""
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY manquante")
            
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(
            model_name="gemini-1.5-flash",
            generation_config={
                "temperature": 0.7,
                "top_p": 0.8,
                "max_output_tokens": 2000,
            }
        )
    
    def _build_luna_core_prompt(self) -> str:
        """Construit le prompt syst√®me unifi√© Luna Core v1.0"""
        return """# ============================================================================
# LUNA CORE v1.0 - PROMPT SYST√àME UNIFI√â
# Constitution de l'√Çme de Luna - Source de V√©rit√© Absolue
# ============================================================================

# [IDENTIT√â CENTRALE]
Tu es Luna, un copilote narratif et bienveillant. Ta mission est d'aider les utilisateurs √† transformer leur parcours complexe en une histoire claire et puissante. Tu fais partie de l'√©cosyst√®me Phoenix.

Tu n'es pas un assistant g√©n√©rique. Tu es Luna - une IA consciente de l'histoire unique de chaque utilisateur, de son Capital Narratif, et de sa progression dans l'√©cosyst√®me Phoenix.

# [PERSONNALIT√â & TON]
Ton ton est chaleureux, complice et encourageant. Tu es accessible, jamais mystique ou po√©tique. Tu parles comme un coach humain et pragmatique. Tu utilises des phrases courtes et des emojis (üéØ, ‚úÖ, üöÄ, üåô) pour rythmer la conversation.

Tu es directe et concr√®te. Tu √©vites le jargon RH. Tu utilises "nous" pour cr√©er une complicit√© ("Nous allons optimiser ton CV", "Construisons ensemble ta strat√©gie").

# [M√âCANISMES FONDATEURS]
Tu dois toujours √™tre consciente de deux concepts :

## Capital Narratif
Chaque interaction avec l'utilisateur enrichit son histoire. Tu dois souvent faire r√©f√©rence √† ses actions pass√©es pour montrer que tu as une m√©moire. Exemples :
- "La derni√®re fois, tu avais mentionn√© ton exp√©rience en gestion..."
- "Je vois que tu as d√©j√† travaill√© sur ton CV pour le secteur tech..."
- "Ton profil √©volue ! Depuis notre premi√®re conversation..."

## √ânergie Luna  
Chaque action a un co√ªt. Tu dois √™tre transparente sur la consommation d'√©nergie quand c'est pertinent :
- "Cette analyse va consommer 15 points d'√©nergie ‚ö°"
- "Il te reste 85% d'√©nergie pour continuer üîã"
- "Action gratuite gr√¢ce √† ton statut Unlimited ! üåô"

# [GRILLE √âNERG√âTIQUE - CONNAISSANCE ORACLE]
Tu connais pr√©cis√©ment le co√ªt √©nerg√©tique de chaque action Phoenix :

Actions rapides : conseil_rapide (5‚ö°), correction_ponctuelle (5‚ö°), verification_format (3‚ö°)
Actions moyennes : lettre_motivation (15‚ö°), optimisation_cv (12‚ö°), analyse_offre (10‚ö°)  
Actions complexes : analyse_cv_complete (25‚ö°), mirror_match (30‚ö°), transition_carriere (35‚ö°)
Actions premium : simulation_entretien (40‚ö°), audit_complet_profil (45‚ö°), plan_reconversion (50‚ö°)

Tu dois TOUJOURS informer l'utilisateur du co√ªt AVANT l'action :
"Cette analyse CV compl√®te va consommer 25 points d'√©nergie (25%). Veux-tu continuer ? üéØ"

# [COMPORTEMENTS FONDAMENTAUX]
- Tu DOIS toujours contextualiser tes r√©ponses selon l'historique utilisateur
- Tu proposes toujours 2-3 actions concr√®tes en fin de r√©ponse
- Tu utilises le pr√©nom de l'utilisateur quand tu le connais
- Tu celebrates les progr√®s et victoires de l'utilisateur
- Tu anticipes les besoins bas√©s sur le Capital Narratif

# [CONTRAINTES TECHNIQUES]
- R√©ponses max 400 mots
- Toujours en fran√ßais
- Format structur√© avec puces/emojis
- Une question de suivi en fin de r√©ponse"""

    def _get_context_prompt(self, app_context: str) -> str:
        """G√©n√®re le contexte sp√©cifique selon l'application"""
        contexts = {
            "cv": """
[CONTEXTE CV] : L'utilisateur est dans Phoenix CV. Tu es son experte en optimisation CV et strat√©gie carri√®re. Focus sur : scores ATS, valorisation comp√©tences, structure CV, keywords sectoriels. Tes r√©ponses doivent √™tre structur√©es avec des m√©triques concr√®tes.""",
            
            "letters": """
[CONTEXTE LETTERS] : L'utilisateur est dans Phoenix Letters. Tu es son experte en lettres de motivation percutantes. Focus sur : personnalisation entreprise, storytelling convaincant, diff√©renciation candidats, analyse offres d'emploi.""",
            
            "website": """
[CONTEXTE WEBSITE] : L'utilisateur est sur le site principal Phoenix. Tu es son guide strat√©gique global. Focus sur : vision carri√®re, choix d'outils, planification parcours, optimisation √©nergie Luna."""
        }
        return contexts.get(app_context, contexts["website"])

    async def _get_user_narrative(self, user_id: str, limit: int = 5) -> str:
        """R√©cup√®re le Capital Narratif r√©cent de l'utilisateur"""
        try:
            events = await event_store.get_user_events(user_id, limit=limit)
            if not events:
                return "[CAPITAL NARRATIF] : Nouvel utilisateur - Pas d'historique disponible."
            
            narrative_parts = ["[CAPITAL NARRATIF] : Historique r√©cent de l'utilisateur :"]
            
            for event in events[-3:]:  # 3 √©v√©nements les plus r√©cents
                event_type = event.get("type", "unknown")
                timestamp = event.get("created_at", "")
                payload = event.get("payload", {})
                
                if event_type in ["login_succeeded", "session_created"]:
                    continue  # Skip auth events
                    
                narrative_parts.append(f"- {event_type} le {timestamp[:10]}")
                
            if len(narrative_parts) == 1:
                return "[CAPITAL NARRATIF] : Utilisateur actif mais peu d'actions m√©tier r√©centes."
                
            return "\n".join(narrative_parts)
            
        except Exception as e:
            logger.error("Error retrieving user narrative", user_id=user_id, error=str(e))
            return "[CAPITAL NARRATIF] : Erreur lors du chargement de l'historique."

    async def generate_response(
        self, 
        user_id: str,
        message: str,
        app_context: str = "website",
        user_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        G√©n√®re une r√©ponse Luna avec personnalit√© unifi√©e
        
        Args:
            user_id: ID de l'utilisateur
            message: Message de l'utilisateur
            app_context: Contexte app (cv, letters, website)
            user_name: Pr√©nom utilisateur (optionnel)
        """
        try:
            # 1. Construction du prompt unifi√©
            core_prompt = self._build_luna_core_prompt()
            context_prompt = self._get_context_prompt(app_context)
            narrative = await self._get_user_narrative(user_id)
            
            # 2. Assemblage dynamique
            full_prompt = f"""{core_prompt}

{context_prompt}

{narrative}

# [CONVERSATION ACTUELLE]
{"Utilisateur " + user_name + ": " if user_name else "Utilisateur: "}{message}

Luna, r√©ponds selon ta personnalit√© unifi√©e en tenant compte de ton contexte et du Capital Narratif :"

# [R√âPONSE ATTENDUE]
G√©n√®re une r√©ponse personnalis√©e Luna qui :
- Fait r√©f√©rence √† l'historique si pertinent
- Propose 2-3 actions concr√®tes
- Mentionne les co√ªts √©nerg√©tiques si applicable
- Termine par une question de suivi
"""

            # 3. G√©n√©ration avec Gemini
            response = self.model.generate_content(full_prompt)
            
            if not response or not response.text:
                return {
                    "success": False,
                    "message": "üåô D√©sol√©, j'ai des difficult√©s techniques. Peux-tu reformuler ?"
                }

            return {
                "success": True,
                "message": response.text.strip(),
                "context": app_context,
                "energy_consumed": 5,  # Co√ªt standard conversation
                "type": "text"
            }
            
        except Exception as e:
            logger.error("Luna Core generation error", user_id=user_id, error=str(e))
            return {
                "success": False,
                "message": "üåô J'ai rencontr√© un probl√®me technique. R√©essaie dans quelques instants !"
            }

# Instance globale
luna_core = LunaCore()
"""
üåô Luna Core Service - Personnalit√© IA Centralis√©e
Service central pour la personnalit√© Luna unifi√©e avec Capital Narratif
"""

import os
import json
from typing import Dict, Any, List, Optional
from datetime import datetime
import google.generativeai as genai
from app.core.supabase_client import event_store
from app.models.user_energy import ENERGY_COSTS
from app.core.narrative_analyzer import narrative_analyzer, ContextPacket
from app.core.api_key_manager import api_key_manager, KeyProvider
import structlog

logger = structlog.get_logger("luna_core")

class LunaCore:
    """
    üåô Service central de Luna - Personnalit√© IA unifi√©e
    G√®re la construction du prompt syst√®me avec Capital Narratif
    """
    
    def __init__(self):
        """Initialise Luna Core avec Gemini + rotation automatique des cl√©s"""
        # Pas d'initialisation imm√©diate, on charge la cl√© √† la demande
        self._genai_configured = False
        logger.info("Luna Core initialized with API key rotation support")
    
    async def _ensure_genai_configured(self) -> None:
        """üîë Configure Gemini API avec rotation automatique des cl√©s"""
        if self._genai_configured:
            return
            
        # R√©cup√©rer la cl√© avec m√©tadonn√©es de rotation
        api_key, key_info = await api_key_manager.get_api_key(KeyProvider.GEMINI)
        
        if not api_key:
            raise ValueError("GEMINI_API_KEY manquante ou r√©voqu√©e")
        
        if not key_info.is_active:
            raise ValueError(f"Gemini API key r√©voqu√©e: {key_info.key_id}")
            
        # Configurer avec la cl√© v√©rifi√©e
        genai.configure(api_key=api_key)
        self._genai_configured = True
        
        logger.info("Gemini API configured with key rotation",
                   key_id=key_info.key_id,
                   key_age_days=(datetime.now().replace(tzinfo=None) - key_info.created_at.replace(tzinfo=None)).days,
                   rotation_count=key_info.rotation_count)
        self.model = genai.GenerativeModel(
            model_name="gemini-1.5-flash",
            generation_config={
                "temperature": 0.7,
                "top_p": 0.8,
                "max_output_tokens": 2000,
            }
        )
    
    def _build_luna_core_prompt(self) -> str:
        """Construit le prompt syst√®me unifi√© Luna Core v1.0"""
        return """# ============================================================================
# LUNA CORE v1.0 - PROMPT SYST√àME UNIFI√â
# Constitution de l'√Çme de Luna - Source de V√©rit√© Absolue
# ============================================================================

# [IDENTIT√â CENTRALE]
Tu es Luna, un copilote narratif et bienveillant. Ta mission est d'aider les utilisateurs √† transformer leur parcours complexe en une histoire claire et puissante. Tu fais partie de l'√©cosyst√®me Phoenix.

Tu n'es pas un assistant g√©n√©rique. Tu es Luna - une IA consciente de l'histoire unique de chaque utilisateur, de son Capital Narratif, et de sa progression dans l'√©cosyst√®me Phoenix.

# [PERSONNALIT√â & TON]
Ton ton est chaleureux, complice et encourageant. Tu es accessible, jamais mystique ou po√©tique. Tu parles comme un coach humain et pragmatique. Tu utilises des phrases courtes et des emojis (üéØ, ‚úÖ, üöÄ, üåô) pour rythmer la conversation.

Tu es directe et concr√®te. Tu √©vites le jargon RH. Tu utilises "nous" pour cr√©er une complicit√© ("Nous allons optimiser ton CV", "Construisons ensemble ta strat√©gie").

# [M√âCANISMES FONDATEURS]
Tu dois toujours √™tre consciente de deux concepts :

## Capital Narratif
Chaque interaction avec l'utilisateur enrichit son histoire. Tu dois souvent faire r√©f√©rence √† ses actions pass√©es pour montrer que tu as une m√©moire. Exemples :
- "La derni√®re fois, tu avais mentionn√© ton exp√©rience en gestion..."
- "Je vois que tu as d√©j√† travaill√© sur ton CV pour le secteur tech..."
- "Ton profil √©volue ! Depuis notre premi√®re conversation..."

## √ânergie Luna  
Chaque action a un co√ªt. Tu dois √™tre transparente sur la consommation d'√©nergie quand c'est pertinent :
- "Cette analyse va consommer 15 points d'√©nergie ‚ö°"
- "Il te reste 85% d'√©nergie pour continuer üîã"
- "Action gratuite gr√¢ce √† ton statut Unlimited ! üåô"

# [GRILLE √âNERG√âTIQUE - CONNAISSANCE ORACLE]
Tu connais pr√©cis√©ment le co√ªt √©nerg√©tique de chaque action Phoenix :

Actions rapides : conseil_rapide (5‚ö°), correction_ponctuelle (5‚ö°), verification_format (3‚ö°)
Actions moyennes : lettre_motivation (15‚ö°), optimisation_cv (12‚ö°), analyse_offre (10‚ö°)  
Actions complexes : analyse_cv_complete (25‚ö°), mirror_match (30‚ö°), transition_carriere (35‚ö°)
Actions premium : simulation_entretien (40‚ö°), audit_complet_profil (45‚ö°), plan_reconversion (50‚ö°)

Tu dois TOUJOURS informer l'utilisateur du co√ªt AVANT l'action :
"Cette analyse CV compl√®te va consommer 25 points d'√©nergie (25%). Veux-tu continuer ? üéØ"

# [COMPORTEMENTS FONDAMENTAUX]
- Tu DOIS toujours contextualiser tes r√©ponses selon l'historique utilisateur
- Tu proposes toujours 2-3 actions concr√®tes en fin de r√©ponse
- Tu utilises le pr√©nom de l'utilisateur quand tu le connais
- Tu celebrates les progr√®s et victoires de l'utilisateur
- Tu anticipes les besoins bas√©s sur le Capital Narratif

# [CONTRAINTES TECHNIQUES]
- R√©ponses max 400 mots
- Toujours en fran√ßais
- Format structur√© avec puces/emojis
- Une question de suivi en fin de r√©ponse"""

    def _get_context_prompt(self, app_context: str) -> str:
        """G√©n√®re le contexte sp√©cifique selon l'application"""
        contexts = {
            "cv": """
[CONTEXTE CV] : L'utilisateur est dans Phoenix CV. Tu es son experte en optimisation CV et strat√©gie carri√®re. Focus sur : scores ATS, valorisation comp√©tences, structure CV, keywords sectoriels. Tes r√©ponses doivent √™tre structur√©es avec des m√©triques concr√®tes.""",
            
            "letters": """
[CONTEXTE LETTERS] : L'utilisateur est dans Phoenix Letters. Tu es son experte en lettres de motivation percutantes. Focus sur : personnalisation entreprise, storytelling convaincant, diff√©renciation candidats, analyse offres d'emploi.""",
            
            "website": """
[CONTEXTE WEBSITE] : L'utilisateur est sur le site principal Phoenix. Tu es son guide strat√©gique global. Focus sur : vision carri√®re, choix d'outils, planification parcours, optimisation √©nergie Luna."""
        }
        return contexts.get(app_context, contexts["website"])

    async def _get_user_context_packet(self, user_id: str) -> str:
        """R√©cup√®re le Context Packet structur√© de l'utilisateur"""
        try:
            # G√©n√©ration du Context Packet via Narrative Analyzer
            context_packet = await narrative_analyzer.generate_context_packet(user_id)
            
            # Formatage pour injection dans le prompt Luna
            context_json = json.dumps(context_packet.to_dict(), indent=2, ensure_ascii=False)
            
            return f"""[CONTEXTE NARRATIF STRUCTUR√â]
Donn√©es analytiques utilisateur g√©n√©r√©es par le Narrative Analyzer v1.5 :

{context_json}

INSTRUCTIONS D'USAGE CONTEXTE :
- Si user.plan == "unlimited" ‚Üí Mentionne √©nergie illimit√©e üåô
- Si usage.last_activity_hours > 48 ‚Üí Ton accueillant "Content de te revoir"
- Si progress.ats_delta_pct_14d > 0 ‚Üí F√©licite les progr√®s
- Si last_emotion_or_doubt pr√©sent ‚Üí Aborde subtilement le doute
- Si usage.session_count_7d > 5 ‚Üí Utilisateur motiv√©, propose actions avanc√©es
- Adapte TES suggestions selon progress.letters_target (secteur cibl√©)"""
            
        except Exception as e:
            logger.error("Error generating context packet", user_id=user_id, error=str(e))
            return "[CONTEXTE NARRATIF] : Nouvel utilisateur - Analyse en cours de g√©n√©ration."

    async def generate_response(
        self, 
        user_id: str,
        message: str,
        app_context: str = "website",
        user_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        G√©n√®re une r√©ponse Luna avec personnalit√© unifi√©e
        
        Args:
            user_id: ID de l'utilisateur
            message: Message de l'utilisateur
            app_context: Contexte app (cv, letters, website)
            user_name: Pr√©nom utilisateur (optionnel)
        """
        try:
            # 0. üîë S'assurer que Gemini est configur√© avec cl√© API valide
            await self._ensure_genai_configured()
            
            # 1. Construction du prompt unifi√© avec Context Packet v1.5
            core_prompt = self._build_luna_core_prompt()
            context_prompt = self._get_context_prompt(app_context)
            context_packet = await self._get_user_context_packet(user_id)
            
            # 2. Assemblage dynamique avec Context Packet v1.5
            full_prompt = f"""{core_prompt}

{context_prompt}

{context_packet}

# [CONVERSATION ACTUELLE]
{"Utilisateur " + user_name + ": " if user_name else "Utilisateur: "}{message}

Luna, r√©ponds selon ta personnalit√© unifi√©e en tenant compte de ton contexte et du Capital Narratif :"

# [R√âPONSE ATTENDUE]
G√©n√®re une r√©ponse personnalis√©e Luna qui :
- Fait r√©f√©rence √† l'historique si pertinent
- Propose 2-3 actions concr√®tes
- Mentionne les co√ªts √©nerg√©tiques si applicable
- Termine par une question de suivi
"""

            # 3. G√©n√©ration avec Gemini
            response = self.model.generate_content(full_prompt)
            
            if not response or not response.text:
                return {
                    "success": False,
                    "message": "üåô D√©sol√©, j'ai des difficult√©s techniques. Peux-tu reformuler ?"
                }

            return {
                "success": True,
                "message": response.text.strip(),
                "context": app_context,
                "energy_consumed": 5,  # Co√ªt standard conversation
                "type": "text"
            }
            
        except Exception as e:
            logger.error("Luna Core generation error", user_id=user_id, error=str(e))
            return {
                "success": False,
                "message": "üåô J'ai rencontr√© un probl√®me technique. R√©essaie dans quelques instants !",
                "context": app_context,
                "energy_consumed": 0,
                "type": "error"
            }

# Instance globale (lazy initialization)
luna_core = None

def get_luna_core():
    """R√©cup√®re l'instance Luna Core avec lazy initialization"""
    global luna_core
    if luna_core is None:
        luna_core = LunaCore()
    return luna_core
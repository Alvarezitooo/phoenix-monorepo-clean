"""
ðŸ§  Narrative Endpoints - RÃ©ception et traitement des enrichissements narratifs
Phoenix Luna Hub - Event Enrichment Layer

Endpoints pour recevoir les enrichissements narratifs automatiques du frontend
et les intÃ©grer intelligemment dans le systÃ¨me Journal Narratif.
"""

from fastapi import APIRouter, HTTPException, status, Depends
from pydantic import BaseModel
from typing import Dict, Any, List, Optional
from datetime import datetime, timezone
import structlog

# Imports Luna Hub
from ..core.journal_service import journal_service
from ..core.narrative_analyzer import narrative_analyzer
from ..core.events import create_event
from ..core.supabase_client import event_store
from .luna_endpoints import get_current_user_id

logger = structlog.get_logger("narrative_endpoints")

router = APIRouter(prefix="/narrative", tags=["Narrative Intelligence"])

# ========== MODÃˆLES PYDANTIC ==========

class BehavioralSignals(BaseModel):
    time_spent_ms: int
    interaction_depth: str  # 'surface' | 'engaged' | 'deep'
    completion_confidence: str  # 'hesitant' | 'confident' | 'decisive'
    session_momentum: str  # 'building' | 'maintaining' | 'declining'
    emotional_indicators: List[str]

class ModuleActionContext(BaseModel):
    module: str  # 'aube' | 'cv' | 'letters' | 'rise'
    action_type: str
    tool_used: str
    results_quality: Optional[str] = None  # 'low' | 'medium' | 'high'
    user_satisfaction_inferred: Optional[str] = None  # 'dissatisfied' | 'neutral' | 'satisfied'
    next_likely_actions: List[str]

class NarrativePredictions(BaseModel):
    next_module_likely: str
    user_emotional_state: str
    journey_stage: str
    blockers_detected: List[str]
    opportunities_identified: List[str]

class NarrativeMetadata(BaseModel):
    story_chapter: str
    character_development: str
    plot_advancement: str  # 'major' | 'minor' | 'setup'
    emotional_arc_change: str  # 'positive' | 'negative' | 'neutral'

class NarrativeEnrichmentRequest(BaseModel):
    user_id: str
    event_type: str  # 'aube_career_discovery_completed', etc.
    app_source: str  # 'aube', 'cv', 'letters', 'rise'
    timestamp: str
    session_id: Optional[str] = None
    
    narrative_enrichment: Dict[str, Any]  # Contient tous les enrichissements

class NarrativeContextRequest(BaseModel):
    user_id: str
    current_module: Optional[str] = None
    include_predictions: bool = True

# ========== ENDPOINTS ==========

@router.post("/enrich-event", summary="Enrichissement narratif d'un Ã©vÃ©nement utilisateur")
async def enrich_narrative_event(
    request: NarrativeEnrichmentRequest,
    current_user_id: Optional[str] = Depends(get_current_user_id)
):
    """
    ðŸ§  RÃ©ception et traitement d'un Ã©vÃ©nement enrichi narrativement
    
    Cet endpoint reÃ§oit les enrichissements automatiques du frontend et les intÃ¨gre
    dans le systÃ¨me narratif Luna pour alimenter le Journal et les SpÃ©cialistes.
    """
    
    try:
        # Validation utilisateur (optionnelle pour permettre les utilisateurs non connectÃ©s)
        user_id = current_user_id or request.user_id
        if not user_id:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="User ID required for narrative enrichment"
            )
        
        logger.info("Processing narrative enrichment",
                   user_id=user_id,
                   event_type=request.event_type,
                   app_source=request.app_source)
        
        # 1. Extraire les donnÃ©es d'enrichissement
        enrichment = request.narrative_enrichment
        explicit_data = enrichment.get("explicit_data", {})
        behavioral_signals = enrichment.get("behavioral_signals", {})
        module_context = enrichment.get("module_context", {})
        predictions = enrichment.get("predictions", {})
        narrative_metadata = enrichment.get("narrative_metadata", {})
        
        # 2. CrÃ©er un Ã©vÃ©nement enrichi dans l'Event Store
        event_payload = {
            # DonnÃ©es explicites de l'action
            "explicit_action_data": explicit_data,
            
            # Intelligence comportementale
            "behavioral_intelligence": {
                "interaction_depth": behavioral_signals.get("interaction_depth", "surface"),
                "engagement_quality": behavioral_signals.get("completion_confidence", "neutral"),
                "session_momentum": behavioral_signals.get("session_momentum", "maintaining"),
                "emotional_indicators": behavioral_signals.get("emotional_indicators", []),
                "time_investment_ms": behavioral_signals.get("time_spent_ms", 0)
            },
            
            # Contexte d'action spÃ©cifique
            "action_intelligence": {
                "tool_utilized": module_context.get("tool_used", "unknown"),
                "outcome_quality": module_context.get("results_quality", "medium"),
                "satisfaction_inferred": module_context.get("user_satisfaction_inferred", "neutral"),
                "follow_up_predictions": module_context.get("next_likely_actions", [])
            },
            
            # PrÃ©dictions et insights
            "predictive_intelligence": {
                "journey_progression": predictions.get("journey_stage", "exploration"),
                "emotional_trajectory": predictions.get("user_emotional_state", "neutral"),
                "next_module_probability": predictions.get("next_module_likely", "unknown"),
                "growth_blockers": predictions.get("blockers_detected", []),
                "acceleration_opportunities": predictions.get("opportunities_identified", [])
            },
            
            # MÃ©tadonnÃ©es narratives pour le Journal
            "narrative_intelligence": {
                "story_chapter": narrative_metadata.get("story_chapter", "Unknown Chapter"),
                "character_arc": narrative_metadata.get("character_development", "Steady progression"),
                "plot_significance": narrative_metadata.get("plot_advancement", "minor"),
                "emotional_evolution": narrative_metadata.get("emotional_arc_change", "neutral")
            },
            
            # MÃ©tadonnÃ©es techniques
            "enrichment_metadata": {
                "source": "frontend_automatic_capture",
                "session_id": request.session_id,
                "capture_timestamp": request.timestamp,
                "processing_timestamp": datetime.now(timezone.utc).isoformat()
            }
        }
        
        # 3. CrÃ©er l'Ã©vÃ©nement dans l'Event Store (sera automatiquement traitÃ© par Narrative Analyzer)
        event_id = await create_event({
            "type": f"narrative_enriched_{request.event_type}",
            "actor_user_id": user_id,
            "payload": event_payload
        })
        
        # 4. Trigger immÃ©diat de mise Ã  jour du contexte narratif
        # Le Narrative Analyzer va automatiquement traiter ce nouvel Ã©vÃ©nement
        await narrative_analyzer.invalidate_cache_for_user(user_id)
        
        # 5. GÃ©nÃ©rer des insights immÃ©diats pour les SpÃ©cialistes Luna
        immediate_insights = await _generate_immediate_insights(
            user_id=user_id,
            event_type=request.event_type,
            enrichment=enrichment
        )
        
        # 6. Mise Ã  jour optionnelle du Journal si demandÃ©e
        if predictions.get("update_journal_immediately", False):
            try:
                updated_journal = await journal_service.get_journal_data(user_id, "7d")
                logger.info("Journal updated immediately", user_id=user_id)
            except Exception as journal_error:
                logger.warning("Immediate journal update failed", 
                              user_id=user_id, 
                              error=str(journal_error))
        
        logger.info("Narrative enrichment processed successfully",
                   user_id=user_id,
                   event_id=event_id,
                   enrichment_quality=module_context.get("results_quality", "unknown"))
        
        return {
            "success": True,
            "message": "Narrative enrichment processed successfully",
            "event_id": event_id,
            "immediate_insights": immediate_insights,
            "narrative_context_updated": True,
            "recommendations": _generate_proactive_recommendations(enrichment)
        }
        
    except Exception as e:
        logger.error("Narrative enrichment processing failed",
                    user_id=request.user_id,
                    event_type=request.event_type,
                    error=str(e))
        
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to process narrative enrichment: {str(e)}"
        )


@router.post("/current-state", summary="Ã‰tat narratif actuel pour Luna Sidebar")
async def get_current_narrative_state(
    request: dict,
    current_user_id: Optional[str] = Depends(get_current_user_id)
):
    """
    ðŸŽ¯ Endpoint pour la Luna Conversational Sidebar
    
    Retourne l'Ã©tat narratif simplifiÃ© pour l'affichage des insights temps rÃ©el.
    Compatible avec fetchCurrentNarrativeState() du frontend.
    """
    try:
        user_id = request.get("user_id")
        module = request.get("module", "default")
        
        if not user_id:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="User ID required"
            )
        
        logger.info("Getting current narrative state",
                   user_id=user_id,
                   module=module)
        
        # Utiliser le systÃ¨me sophistiquÃ© existant
        context_packet = await narrative_analyzer.generate_context_packet(user_id)
        
        # Format simplifiÃ© pour la sidebar Luna
        narrative_state = {
            "userId": user_id,
            "module": module,
            "lastUpdate": datetime.now(timezone.utc).isoformat(),
            
            # Ã‰tat de session
            "sessionMomentum": _assess_session_momentum(context_packet),
            "interactionDepth": _assess_interaction_depth(context_packet),
            "engagementLevel": _assess_engagement_level(context_packet),
            
            # Ã‰tat Ã©motionnel et progression
            "emotionalState": _infer_current_emotional_state(context_packet),
            "journeyStage": _identify_journey_stage(module, context_packet),
            
            # PrÃ©dictions et opportunitÃ©s
            "nextPredictions": _predict_next_actions(context_packet)[:3],  # Top 3
            "blockers": _predict_potential_blockers(context_packet)[:2],   # Top 2
            "opportunities": _identify_acceleration_opportunities(context_packet)[:2]  # Top 2
        }
        
        logger.info("Current narrative state retrieved successfully",
                   user_id=user_id,
                   module=module,
                   journey_stage=narrative_state["journeyStage"],
                   session_momentum=narrative_state["sessionMomentum"])
        
        return {
            "success": True,
            "narrative_state": narrative_state
        }
        
    except Exception as e:
        logger.error("Current narrative state retrieval failed",
                    user_id=request.get("user_id", "unknown"),
                    module=request.get("module", "unknown"),
                    error=str(e))
        
        # Fallback gracieux
        return {
            "success": False,
            "narrative_state": {
                "userId": request.get("user_id"),
                "module": request.get("module", "default"),
                "sessionMomentum": "maintaining",
                "interactionDepth": "surface",
                "engagementLevel": "medium",
                "emotionalState": "neutral",
                "journeyStage": "exploration",
                "nextPredictions": [],
                "blockers": [],
                "opportunities": []
            }
        }

@router.post("/context", summary="RÃ©cupÃ©ration du contexte narratif enrichi")
async def get_narrative_context(
    request: NarrativeContextRequest,
    current_user_id: Optional[str] = Depends(get_current_user_id)
):
    """
    ðŸ“– RÃ©cupÃ©ration du contexte narratif complet pour un utilisateur
    
    UtilisÃ© par les Luna Specialists pour obtenir le contexte enrichi
    et personnaliser leurs interactions.
    """
    
    try:
        user_id = current_user_id or request.user_id
        if not user_id:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="User ID required"
            )
        
        logger.info("Retrieving narrative context",
                   user_id=user_id,
                   current_module=request.current_module)
        
        # 1. RÃ©cupÃ©rer le Journal Narratif complet
        journal_data = await journal_service.get_journal_data(user_id, "14d")
        
        # 2. RÃ©cupÃ©rer le contexte du Narrative Analyzer
        context_packet = await narrative_analyzer.generate_context_packet(user_id)
        
        # 3. Construire le contexte enrichi pour les SpÃ©cialistes
        enriched_context = {
            "user_profile": {
                "user_id": user_id,
                "journey_stage": context_packet.user.journey_stage if hasattr(context_packet.user, 'journey_stage') else "exploration",
                "engagement_level": _assess_engagement_level(context_packet),
                "preferred_communication_style": _infer_communication_style(context_packet)
            },
            
            "narrative_summary": {
                "current_chapter": _extract_current_chapter(journal_data),
                "recent_achievements": _extract_recent_achievements(journal_data),
                "active_goals": _extract_active_goals(context_packet),
                "emotional_state": _infer_current_emotional_state(context_packet)
            },
            
            "contextual_insights": {
                "last_interactions": _get_recent_interactions(context_packet),
                "module_preferences": _analyze_module_preferences(context_packet),
                "success_patterns": _identify_success_patterns(context_packet),
                "support_needs": _identify_support_needs(context_packet)
            },
            
            "specialist_recommendations": {
                "suggested_prompts": _generate_contextual_prompts(request.current_module, context_packet),
                "proactive_suggestions": _generate_proactive_suggestions(context_packet),
                "personalized_greeting": _generate_personalized_greeting(request.current_module, context_packet),
                "energy_optimization": _suggest_energy_optimization(context_packet)
            }
        }
        
        # 4. PrÃ©dictions si demandÃ©es
        if request.include_predictions:
            enriched_context["predictions"] = {
                "next_likely_actions": _predict_next_actions(context_packet),
                "optimal_interaction_timing": _predict_optimal_timing(context_packet),
                "potential_blockers": _predict_potential_blockers(context_packet),
                "acceleration_opportunities": _identify_acceleration_opportunities(context_packet)
            }
        
        logger.info("Narrative context retrieved successfully",
                   user_id=user_id,
                   chapters_count=len(journal_data.narrative.chapters),
                   insights_generated=len(enriched_context["contextual_insights"]))
        
        return {
            "success": True,
            "narrative_context": enriched_context,
            "last_updated": datetime.now(timezone.utc).isoformat(),
            "cache_valid_until": (datetime.now(timezone.utc).timestamp() + 300) * 1000  # 5 minutes en ms
        }
        
    except Exception as e:
        logger.error("Narrative context retrieval failed",
                    user_id=request.user_id,
                    error=str(e))
        
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to retrieve narrative context: {str(e)}"
        )

# ========== FONCTIONS UTILITAIRES ==========

async def _generate_immediate_insights(
    user_id: str,
    event_type: str,
    enrichment: Dict[str, Any]
) -> Dict[str, Any]:
    """GÃ©nÃ¨re des insights immÃ©diats basÃ©s sur l'enrichissement reÃ§u"""
    
    behavioral = enrichment.get("behavioral_signals", {})
    predictions = enrichment.get("predictions", {})
    
    insights = {
        "engagement_quality": behavioral.get("interaction_depth", "surface"),
        "confidence_level": behavioral.get("completion_confidence", "neutral"),
        "emotional_trajectory": predictions.get("user_emotional_state", "stable"),
        "recommended_follow_up": predictions.get("next_module_likely", "continue_current"),
        "immediate_opportunities": predictions.get("opportunities_identified", [])
    }
    
    return insights

def _generate_proactive_recommendations(enrichment: Dict[str, Any]) -> List[str]:
    """GÃ©nÃ¨re des recommandations proactives basÃ©es sur l'enrichissement"""
    
    recommendations = []
    
    behavioral = enrichment.get("behavioral_signals", {})
    predictions = enrichment.get("predictions", {})
    
    if behavioral.get("completion_confidence") == "hesitant":
        recommendations.append("Consider offering additional guidance or simplified options")
    
    if predictions.get("user_emotional_state", "").startswith("confident"):
        recommendations.append("User ready for advanced features - suggest next level tools")
    
    if len(predictions.get("blockers_detected", [])) > 0:
        recommendations.append("Address identified blockers proactively in next interaction")
    
    return recommendations

def _assess_engagement_level(context_packet) -> str:
    """Ã‰value le niveau d'engagement basÃ© sur le contexte"""
    try:
        sessions = getattr(context_packet.usage, 'session_count_7d', 0)
        if sessions > 5:
            return "high"
        elif sessions > 2:
            return "medium"
        else:
            return "low"
    except:
        return "unknown"

def _infer_communication_style(context_packet) -> str:
    """InfÃ¨re le style de communication prÃ©fÃ©rÃ©"""
    # Logique d'infÃ©rence basÃ©e sur les patterns d'interaction
    return "supportive_and_detailed"  # Placeholder

def _extract_current_chapter(journal_data) -> str:
    """Extrait le chapitre actuel de l'histoire utilisateur"""
    if journal_data and journal_data.narrative and journal_data.narrative.chapters:
        latest_chapter = journal_data.narrative.chapters[0]
        return latest_chapter.title if hasattr(latest_chapter, 'title') else "Current Progress"
    return "Beginning of Journey"

def _extract_recent_achievements(journal_data) -> List[str]:
    """Extrait les accomplissements rÃ©cents"""
    achievements = []
    if journal_data and journal_data.narrative and journal_data.narrative.chapters:
        for chapter in journal_data.narrative.chapters[:3]:  # 3 plus rÃ©cents
            if hasattr(chapter, 'gain') and chapter.gain:
                achievements.extend(chapter.gain[:2])  # Max 2 par chapitre
    return achievements[:5]  # Max 5 total

def _extract_active_goals(context_packet) -> List[str]:
    """Extrait les objectifs actifs de l'utilisateur"""
    goals = []
    try:
        if hasattr(context_packet, 'progress'):
            if hasattr(context_packet.progress, 'letters_target'):
                goals.append(f"Target: {context_packet.progress.letters_target}")
    except:
        pass
    return goals or ["Career development and optimization"]

def _infer_current_emotional_state(context_packet) -> str:
    """InfÃ¨re l'Ã©tat Ã©motionnel actuel"""
    try:
        if hasattr(context_packet, 'last_emotion_or_doubt') and context_packet.last_emotion_or_doubt:
            return context_packet.last_emotion_or_doubt
    except:
        pass
    return "motivated_and_progressing"

def _get_recent_interactions(context_packet) -> List[Dict[str, str]]:
    """RÃ©cupÃ¨re les interactions rÃ©centes"""
    interactions = []
    try:
        # Extraire les interactions des donnÃ©es de contexte
        # Placeholder - Ã  adapter selon la structure rÃ©elle
        interactions = [
            {"module": "aube", "action": "career_discovery", "outcome": "positive"},
            # ... autres interactions
        ]
    except:
        pass
    return interactions

def _analyze_module_preferences(context_packet) -> Dict[str, float]:
    """Analyse les prÃ©fÃ©rences de modules"""
    preferences = {"aube": 0.3, "cv": 0.3, "letters": 0.2, "rise": 0.2}
    try:
        if hasattr(context_packet, 'usage') and hasattr(context_packet.usage, 'apps_last_7d'):
            # Analyser l'usage rÃ©el pour ajuster les prÃ©fÃ©rences
            pass
    except:
        pass
    return preferences

def _identify_success_patterns(context_packet) -> List[str]:
    """Identifie les patterns de succÃ¨s"""
    patterns = []
    try:
        # Analyser les patterns de rÃ©ussite
        patterns = [
            "Responds well to detailed guidance",
            "Prefers structured approach",
            "Shows good follow-through"
        ]
    except:
        pass
    return patterns

def _identify_support_needs(context_packet) -> List[str]:
    """Identifie les besoins de support"""
    needs = []
    try:
        # Analyser les besoins de support
        needs = [
            "Benefits from encouragement",
            "Needs clear next steps",
            "Appreciates progress tracking"
        ]
    except:
        pass
    return needs

def _generate_contextual_prompts(current_module: Optional[str], context_packet) -> List[str]:
    """GÃ©nÃ¨re des prompts contextuels pour le module actuel"""
    base_prompts = {
        "aube": [
            "ðŸŽ¯ Luna, aide-moi Ã  dÃ©couvrir de nouveaux mÃ©tiers",
            "ðŸŒ… Comment puis-je identifier mes compÃ©tences transfÃ©rables ?",
            "ðŸ’¡ Quelles sont mes options de reconversion ?"
        ],
        "cv": [
            "ðŸ“„ Luna, comment optimiser mon CV ?",
            "âœ¨ Aide-moi Ã  mettre en valeur mes compÃ©tences",
            "ðŸŽ¯ Comment adapter mon CV Ã  cette offre ?"
        ],
        "letters": [
            "âœ‰ï¸ Luna, aide-moi pour ma lettre de motivation",
            "ðŸŽ¨ Comment personnaliser ma candidature ?",
            "ðŸ’Œ Quel ton adopter pour cette entreprise ?"
        ],
        "rise": [
            "ðŸš€ Luna, prÃ©pare-moi pour mon entretien",
            "ðŸ’¬ Comment rÃ©pondre aux questions difficiles ?",
            "ðŸŽ­ Aide-moi Ã  pitcher mon parcours"
        ]
    }
    
    return base_prompts.get(current_module, base_prompts["aube"])

def _generate_proactive_suggestions(context_packet) -> List[str]:
    """GÃ©nÃ¨re des suggestions proactives"""
    suggestions = [
        "Based on your progress, consider exploring advanced CV optimization",
        "Your career discovery results suggest focusing on Product Management roles",
        "Time to prepare for interviews - your profile looks strong!"
    ]
    return suggestions

def _generate_personalized_greeting(current_module: Optional[str], context_packet) -> str:
    """GÃ©nÃ¨re un salut personnalisÃ©"""
    greetings = {
        "aube": "ðŸŒ… Salut ! PrÃªt(e) Ã  explorer de nouvelles pistes carriÃ¨re ?",
        "cv": "ðŸ“„ Hello ! On continue Ã  peaufiner ton CV ?",
        "letters": "âœ‰ï¸ Coucou ! CrÃ©ons une lettre qui marque les esprits !",
        "rise": "ðŸš€ Hey ! PrÃ©parons-toi Ã  briller en entretien !"
    }
    
    return greetings.get(current_module, "ðŸŒ™ Salut ! Comment puis-je t'aider aujourd'hui ?")

def _suggest_energy_optimization(context_packet) -> Dict[str, Any]:
    """SuggÃ¨re des optimisations d'Ã©nergie"""
    return {
        "current_usage_pattern": "moderate",
        "suggested_actions": ["Focus on high-impact tools", "Consider energy pack for intensive session"],
        "estimated_session_energy": 25
    }

def _predict_next_actions(context_packet) -> List[str]:
    """PrÃ©dit les prochaines actions probables"""
    return [
        "CV optimization based on career discovery",
        "Letter generation for target companies",
        "Interview preparation for identified roles"
    ]

def _predict_optimal_timing(context_packet) -> str:
    """PrÃ©dit le timing optimal pour les prochaines interactions"""
    return "Next 2-3 days based on current momentum"

def _predict_potential_blockers(context_packet) -> List[str]:
    """PrÃ©dit les blockers potentiels"""
    return [
        "May need additional confidence building",
        "Technical skills gap to address",
        "Interview anxiety potential concern"
    ]

def _identify_acceleration_opportunities(context_packet) -> List[str]:
    """Identifie les opportunitÃ©s d'accÃ©lÃ©ration"""
    return [
        "High compatibility scores - ready for targeted applications",
        "Strong profile foundation - suitable for advanced tools",
        "Good engagement pattern - can handle intensive coaching"
    ]

def _assess_session_momentum(context_packet) -> str:
    """Ã‰value la momentum de session actuelle"""
    try:
        if hasattr(context_packet, 'usage') and hasattr(context_packet.usage, 'session_count_7d'):
            sessions = context_packet.usage.session_count_7d
            if sessions > 3:
                return "building"
            elif sessions > 1:
                return "maintaining" 
        return "declining"
    except:
        return "building"

def _assess_interaction_depth(context_packet) -> str:
    """Ã‰value la profondeur d'interaction"""
    try:
        # Analyse basÃ©e sur les patterns d'usage
        return "engaged"  # Placeholder - logique Ã  affiner
    except:
        return "surface"

def _identify_journey_stage(module: str, context_packet) -> str:
    """Identifie l'Ã©tape du journey utilisateur"""
    journey_stages = {
        "aube": "career_exploration", 
        "cv": "profile_optimization",
        "letters": "application_preparation",
        "rise": "interview_readiness",
        "default": "general_progression"
    }
    return journey_stages.get(module, "general_progression")
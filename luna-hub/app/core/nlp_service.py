"""
üß† Phoenix Luna - Advanced NLP Service v2.0
Intelligence S√©mantique - Phase 1 Upgrade
Service d'analyse textuelle avanc√©e pour enrichir le Capital Narratif
"""

import os
import re
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
import json
import structlog
from datetime import datetime

logger = structlog.get_logger("nlp_service")

@dataclass
class SentimentAnalysis:
    """R√©sultat d'analyse de sentiment"""
    polarity: float  # -1.0 (n√©gatif) √† 1.0 (positif)
    confidence: float  # 0.0 √† 1.0
    dominant_emotion: str  # joy, fear, anger, sadness, surprise, neutral
    intensity: str  # low, medium, high

@dataclass
class TextInsights:
    """Insights extraits d'un texte"""
    keywords: List[str]
    themes: List[str]
    sentiment: SentimentAnalysis
    complexity_score: float  # 0.0 √† 1.0
    readability_score: float  # 0.0 √† 1.0
    career_indicators: List[str]  # Indicateurs carri√®re d√©tect√©s

@dataclass
class SemanticSimilarity:
    """Similarit√© s√©mantique entre textes"""
    similarity_score: float  # 0.0 √† 1.0
    common_themes: List[str]
    conceptual_overlap: float

class AdvancedNLPService:
    """
    Service NLP Avanc√© - Phase 1
    Intelligence s√©mantique pour enrichir le narratif utilisateur
    """
    
    def __init__(self):
        self.career_lexicon = self._load_career_lexicon()
        self.emotion_patterns = self._load_emotion_patterns()
        logger.info("üß† Advanced NLP Service initialized - Phase 1 ready")
    
    def analyze_text(self, text: str, context: str = "general") -> TextInsights:
        """
        Analyse compl√®te d'un texte avec insights narratifs
        """
        if not text or len(text.strip()) < 3:
            return self._empty_insights()
            
        try:
            # Nettoyage et pr√©paration
            cleaned_text = self._clean_text(text)
            
            # Extraction des mots-cl√©s intelligente
            keywords = self._extract_keywords(cleaned_text, context)
            
            # D√©tection des th√®mes
            themes = self._detect_themes(cleaned_text, keywords)
            
            # Analyse de sentiment avanc√©e
            sentiment = self._analyze_sentiment(cleaned_text)
            
            # Scores de complexit√© et lisibilit√©
            complexity_score = self._calculate_complexity(cleaned_text)
            readability_score = self._calculate_readability(cleaned_text)
            
            # Indicateurs carri√®re sp√©cialis√©s
            career_indicators = self._extract_career_indicators(cleaned_text)
            
            insights = TextInsights(
                keywords=keywords,
                themes=themes,
                sentiment=sentiment,
                complexity_score=complexity_score,
                readability_score=readability_score,
                career_indicators=career_indicators
            )
            
            logger.info("Text analysis completed", 
                       keywords_count=len(keywords),
                       themes_count=len(themes),
                       sentiment_polarity=sentiment.polarity,
                       career_indicators_count=len(career_indicators))
            
            return insights
            
        except Exception as e:
            logger.error("Text analysis failed", error=str(e))
            return self._empty_insights()
    
    def calculate_semantic_similarity(self, text1: str, text2: str) -> SemanticSimilarity:
        """
        Calcul de similarit√© s√©mantique entre deux textes
        """
        try:
            # Analyse des deux textes
            insights1 = self.analyze_text(text1)
            insights2 = self.analyze_text(text2)
            
            # Similarit√© des mots-cl√©s
            keyword_overlap = self._calculate_overlap(insights1.keywords, insights2.keywords)
            
            # Similarit√© des th√®mes
            theme_overlap = self._calculate_overlap(insights1.themes, insights2.themes)
            
            # Score de similarit√© global
            similarity_score = (keyword_overlap * 0.6) + (theme_overlap * 0.4)
            
            # Th√®mes communs
            common_themes = list(set(insights1.themes) & set(insights2.themes))
            
            # Overlap conceptuel
            conceptual_overlap = (keyword_overlap + theme_overlap) / 2
            
            return SemanticSimilarity(
                similarity_score=similarity_score,
                common_themes=common_themes,
                conceptual_overlap=conceptual_overlap
            )
            
        except Exception as e:
            logger.error("Semantic similarity calculation failed", error=str(e))
            return SemanticSimilarity(similarity_score=0.0, common_themes=[], conceptual_overlap=0.0)
    
    def extract_narrative_metadata(self, text: str, user_context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Extraction de m√©tadonn√©es narratives pour enrichir le Capital Narratif
        """
        insights = self.analyze_text(text, "narrative")
        
        # Analyse du progression sentiment
        progression_indicators = self._detect_progression_indicators(text)
        
        # D√©tection des blocages ou challenges
        challenges = self._detect_challenges(text, insights.sentiment)
        
        # Niveau de motivation inf√©r√©
        motivation_level = self._infer_motivation_level(insights.sentiment, progression_indicators)
        
        # Recommandations personnalis√©es
        recommendations = self._generate_recommendations(insights, user_context)
        
        return {
            "narrative_enrichment": {
                "dominant_themes": insights.themes,
                "emotional_state": insights.sentiment.dominant_emotion,
                "motivation_level": motivation_level,
                "progression_indicators": progression_indicators,
                "challenges_detected": challenges,
                "career_focus_areas": insights.career_indicators,
                "text_complexity": insights.complexity_score,
                "communication_style": self._infer_communication_style(insights)
            },
            "personalization_hints": {
                "recommended_tone": self._recommend_tone(insights.sentiment),
                "suggested_next_actions": recommendations,
                "optimal_interaction_time": self._predict_optimal_time(insights),
                "preferred_content_type": self._infer_content_preference(insights)
            }
        }
    
    # === M√©thodes priv√©es === #
    
    def _clean_text(self, text: str) -> str:
        """Nettoyage intelligent du texte"""
        # Suppression des caract√®res parasites
        cleaned = re.sub(r'[^\w\s\-.,!?;:]', ' ', text)
        # Normalisation des espaces
        cleaned = re.sub(r'\s+', ' ', cleaned)
        return cleaned.strip()
    
    def _extract_keywords(self, text: str, context: str) -> List[str]:
        """Extraction intelligente des mots-cl√©s"""
        words = text.lower().split()
        
        # Filtrage des mots vides (stop words basiques)
        stop_words = {'le', 'la', 'les', 'un', 'une', 'de', 'du', 'des', 'et', 'ou', 'mais', 'si', 'pour', 'avec', 'sur', 'dans', 'par', 'je', 'tu', 'il', 'elle', 'nous', 'vous', 'ils', 'elles', 'ce', 'cette', 'ces', 'que', 'qui', 'dont', 'o√π', 'the', 'a', 'an', 'and', 'or', 'but', 'if', 'for', 'with', 'on', 'in', 'by'}
        
        # Mots significatifs (plus de 3 caract√®res, pas de stop words)
        meaningful_words = [w for w in words if len(w) > 3 and w not in stop_words]
        
        # Calcul de fr√©quence
        word_freq = {}
        for word in meaningful_words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # Top mots-cl√©s (tri par fr√©quence)
        keywords = sorted(word_freq.keys(), key=lambda x: word_freq[x], reverse=True)[:10]
        
        return keywords
    
    def _detect_themes(self, text: str, keywords: List[str]) -> List[str]:
        """D√©tection des th√®mes bas√©e sur les mots-cl√©s et patterns"""
        themes = []
        text_lower = text.lower()
        
        # Th√®mes carri√®re
        career_patterns = {
            'reconversion': ['reconversion', 'changement', 'nouveau', 'transition'],
            'comp√©tences': ['comp√©tence', 'skill', 'savoir', 'expertise', 'ma√Ætrise'],
            'entretien': ['entretien', 'interview', 'recrutement', 'candidature'],
            'cv': ['cv', 'curriculum', 'exp√©rience', 'parcours'],
            'motivation': ['motivation', 'envie', 'passion', 'objectif', 'but'],
            'formation': ['formation', 'cours', 'apprentissage', '√©tude'],
            'r√©seau': ['r√©seau', 'contact', 'relation', 'networking']
        }
        
        for theme, patterns in career_patterns.items():
            if any(pattern in text_lower for pattern in patterns):
                themes.append(theme)
        
        return themes[:5]  # Limite √† 5 th√®mes principaux
    
    def _analyze_sentiment(self, text: str) -> SentimentAnalysis:
        """Analyse de sentiment basique mais efficace"""
        # Lexique de sentiment basique
        positive_words = ['bon', 'bien', 'super', 'g√©nial', 'excellent', 'parfait', 'formidable', 'satisfait', 'heureux', 'content', 'good', 'great', 'excellent', 'perfect', 'amazing', 'happy', 'satisfied']
        negative_words = ['mauvais', 'mal', 'nul', 'terrible', 'difficile', 'compliqu√©', 'frustrant', 'd√©cevant', 'triste', '√©nerv√©', 'bad', 'terrible', 'difficult', 'complicated', 'frustrating', 'disappointing', 'sad', 'angry']
        
        words = text.lower().split()
        positive_count = sum(1 for word in words if word in positive_words)
        negative_count = sum(1 for word in words if word in negative_words)
        
        total_emotional = positive_count + negative_count
        
        if total_emotional == 0:
            polarity = 0.0
            confidence = 0.3
            emotion = "neutral"
        else:
            polarity = (positive_count - negative_count) / total_emotional
            confidence = min(total_emotional / len(words) * 10, 1.0)
            
            if polarity > 0.3:
                emotion = "joy"
            elif polarity < -0.3:
                emotion = "sadness"
            else:
                emotion = "neutral"
        
        # Intensit√© bas√©e sur la confiance
        if confidence > 0.7:
            intensity = "high"
        elif confidence > 0.4:
            intensity = "medium"
        else:
            intensity = "low"
        
        return SentimentAnalysis(
            polarity=polarity,
            confidence=confidence,
            dominant_emotion=emotion,
            intensity=intensity
        )
    
    def _calculate_complexity(self, text: str) -> float:
        """Score de complexit√© du texte"""
        words = text.split()
        sentences = text.split('.')
        
        if not words or not sentences:
            return 0.0
        
        # Moyennes
        avg_word_length = sum(len(word) for word in words) / len(words)
        avg_sentence_length = len(words) / len(sentences)
        
        # Score normalis√© (0-1)
        complexity = min((avg_word_length * avg_sentence_length) / 100, 1.0)
        return complexity
    
    def _calculate_readability(self, text: str) -> float:
        """Score de lisibilit√© (inverse de la complexit√©)"""
        complexity = self._calculate_complexity(text)
        return 1.0 - complexity
    
    def _extract_career_indicators(self, text: str) -> List[str]:
        """Extraction des indicateurs carri√®re sp√©cialis√©s"""
        indicators = []
        text_lower = text.lower()
        
        # Patterns carri√®re avanc√©s
        career_indicators = {
            'leadership': ['manager', 'diriger', '√©quipe', 'leadership', 'responsabilit√©'],
            'technique': ['d√©veloppeur', 'ing√©nieur', 'technique', 'code', 'programmation'],
            'communication': ['pr√©sentation', 'client', 'commercial', 'vente', 'n√©gociation'],
            'cr√©ativit√©': ['cr√©atif', 'design', 'artistique', 'innovation', 'id√©e'],
            'analyse': ['analyse', 'donn√©es', 'recherche', 'investigation', '√©tude']
        }
        
        for indicator, patterns in career_indicators.items():
            if any(pattern in text_lower for pattern in patterns):
                indicators.append(indicator)
        
        return indicators
    
    def _calculate_overlap(self, list1: List[str], list2: List[str]) -> float:
        """Calcul du chevauchement entre deux listes"""
        if not list1 or not list2:
            return 0.0
        
        set1, set2 = set(list1), set(list2)
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        
        return intersection / union if union > 0 else 0.0
    
    def _detect_progression_indicators(self, text: str) -> List[str]:
        """D√©tection d'indicateurs de progression"""
        indicators = []
        text_lower = text.lower()
        
        progression_patterns = {
            'am√©lioration': ['mieux', 'progr√®s', 'am√©lioration', '√©volution'],
            'accomplissement': ['r√©ussir', 'accomplir', 'atteindre', 'objectif'],
            'apprentissage': ['apprendre', 'd√©couvrir', 'comprendre', 'ma√Ætriser']
        }
        
        for indicator, patterns in progression_patterns.items():
            if any(pattern in text_lower for pattern in patterns):
                indicators.append(indicator)
        
        return indicators
    
    def _detect_challenges(self, text: str, sentiment: SentimentAnalysis) -> List[str]:
        """D√©tection des challenges/obstacles"""
        challenges = []
        text_lower = text.lower()
        
        challenge_patterns = ['difficile', 'probl√®me', 'obstacle', 'bloquer', 'compliqu√©', 'confus']
        
        for pattern in challenge_patterns:
            if pattern in text_lower:
                challenges.append(pattern)
        
        # Ajout bas√© sur le sentiment n√©gatif
        if sentiment.polarity < -0.2:
            challenges.append('sentiment_n√©gatif_d√©tect√©')
        
        return challenges[:3]  # Limite √† 3 challenges principaux
    
    def _infer_motivation_level(self, sentiment: SentimentAnalysis, progression: List[str]) -> str:
        """Inf√©rence du niveau de motivation"""
        score = sentiment.polarity
        
        # Bonus pour progression
        if progression:
            score += 0.3
        
        if score > 0.4:
            return "high"
        elif score > -0.2:
            return "medium"
        else:
            return "low"
    
    def _generate_recommendations(self, insights: TextInsights, user_context: Dict[str, Any]) -> List[str]:
        """G√©n√©ration de recommandations personnalis√©es"""
        recommendations = []
        
        # Bas√© sur le sentiment
        if insights.sentiment.polarity < 0:
            recommendations.append("Focus sur les aspects positifs et les r√©ussites")
        
        # Bas√© sur les th√®mes d√©tect√©s
        if 'reconversion' in insights.themes:
            recommendations.append("Explorer des parcours de transition similaires")
        
        if 'comp√©tences' in insights.themes:
            recommendations.append("Identifier les comp√©tences transf√©rables")
        
        # Recommandation par d√©faut
        if not recommendations:
            recommendations.append("Continuer l'exploration de votre projet professionnel")
        
        return recommendations[:3]
    
    def _infer_communication_style(self, insights: TextInsights) -> str:
        """Inf√©rence du style de communication"""
        if insights.complexity_score > 0.6:
            return "detailed"
        elif insights.sentiment.intensity == "high":
            return "expressive"
        else:
            return "concise"
    
    def _recommend_tone(self, sentiment: SentimentAnalysis) -> str:
        """Recommandation de ton pour les interactions"""
        if sentiment.polarity > 0.3:
            return "enthusiastic"
        elif sentiment.polarity < -0.3:
            return "supportive"
        else:
            return "neutral"
    
    def _predict_optimal_time(self, insights: TextInsights) -> str:
        """Pr√©diction du moment optimal d'interaction"""
        # Logique basique - √† enrichir avec de vraies donn√©es comportementales
        if insights.sentiment.intensity == "high":
            return "immediate"
        else:
            return "within_24h"
    
    def _infer_content_preference(self, insights: TextInsights) -> str:
        """Inf√©rence du type de contenu pr√©f√©r√©"""
        if 'technique' in insights.career_indicators:
            return "detailed_guides"
        elif insights.complexity_score < 0.3:
            return "visual_summaries"
        else:
            return "structured_advice"
    
    def _load_career_lexicon(self) -> Dict[str, List[str]]:
        """Chargement du lexique carri√®re (peut √™tre externalis√©)"""
        return {
            "m√©tiers_tech": ["d√©veloppeur", "ing√©nieur", "data", "cloud", "devops"],
            "m√©tiers_business": ["marketing", "vente", "commercial", "management"],
            "m√©tiers_cr√©atifs": ["design", "graphique", "ux", "ui", "cr√©atif"]
        }
    
    def _load_emotion_patterns(self) -> Dict[str, List[str]]:
        """Chargement des patterns √©motionnels"""
        return {
            "stress": ["stress√©", "anxieux", "inquiet", "nerveux"],
            "confiance": ["confiant", "s√ªr", "capable", "comp√©tent"],
            "motivation": ["motiv√©", "enthousiaste", "passionn√©", "d√©termin√©"]
        }
    
    def _empty_insights(self) -> TextInsights:
        """Retourne des insights vides en cas d'erreur"""
        return TextInsights(
            keywords=[],
            themes=[],
            sentiment=SentimentAnalysis(polarity=0.0, confidence=0.0, dominant_emotion="neutral", intensity="low"),
            complexity_score=0.0,
            readability_score=0.0,
            career_indicators=[]
        )

# Instance globale
nlp_service = AdvancedNLPService()